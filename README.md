# EdgeSoul v3.0 - Emotional AI Chatbot Desktop App

<div align="center">

**Your Personal AI Companion with Emotional Intelligence**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey)]()
[![Python](https://img.shields.io/badge/python-3.9%2B-blue)]()
[![Node](https://img.shields.io/badge/node-18%2B-green)]()

*An intelligent chatbot that understands your emotions and responds with empathy + knowledge*

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Documentation](#-documentation)

</div>

---

## ğŸŒŸ What is EdgeSoul?

EdgeSoul is a **privacy-first AI chatbot** that runs completely on your computer. It combines:
- âœ¨ **Emotional Intelligence** - Detects and responds to your emotions (joy, sadness, anger, fear, love, surprise)
- ğŸ§  **Knowledge Reasoning** - Answers questions using local AI (Ollama)
- ğŸ”’ **100% Private** - Everything runs locally, no data sent to cloud
- ğŸ’° **Completely Free** - No API costs, no subscriptions
- ğŸ“± **Desktop App** - Native app for Windows, macOS, Linux

---

## ğŸš€ Features

### ğŸ­ Emotional Intelligence
- **85%+ Emotion Accuracy** - Advanced ONNX emotion detection model
- **Mixed Emotion Support** - Detects complex feelings like "happy but worried"
- **Context-Aware** - Understands victim/blamed context, negations, fear indicators
- **Empathetic Responses** - Adjusts tone based on your emotional state

### ğŸ§  Knowledge Engine
- **Local AI** - Powered by Ollama (TinyLlama, Phi3, or other models)
- **Offline Capable** - Works without internet after setup
- **Fast Responses** - 10-20 seconds with TinyLlama, 3-5s with Phi3
- **Unlimited Questions** - Ask anything, completely free

### ğŸ¯ Smart Response System
- **Intent Detection** - Recognizes when you want encouragement, calm, or information
- **Action-Oriented** - Provides practical, helpful responses
- **Hybrid Responses** - Combines emotional support with factual knowledge
- **Memory & Learning** - Adapts to your conversation style

### ğŸ–¥ï¸ Desktop Application
- **Cross-Platform** - Windows, macOS, Linux support
- **System Tray** - Minimize to tray, global shortcuts
- **Auto-Start Backend** - No manual server setup needed
- **Dark/Light Theme** - Beautiful ChatGPT-style interface
- **Offline Storage** - IndexedDB for conversation history

---

## ğŸ“‹ Prerequisites

### Required
- **Node.js** 18 or higher
- **Python** 3.9 or higher  
- **Ollama** - [Download from ollama.ai](https://ollama.ai)
- **RAM**: 4GB+ free (2.6GB minimum for TinyLlama)

### Optional
- **Git** - For cloning the repository
- **Code Editor** - VS Code recommended

---

## âš¡ Quick Start

### Option 1: Desktop App (Easiest)

```powershell
# 1. Clone the repository
git clone https://github.com/yourusername/edgesoul.git
cd edgesoul

# 2. Install Ollama and pull a model
ollama pull tinyllama

# 3. Start the desktop app
cd desktop
npm install
npm start
```

The app will automatically start the backend and open the chat interface!

### Option 2: Manual Start

```powershell
# Terminal 1: Start backend
cd backend
pip install -r requirements.txt
python -m uvicorn main:app --reload --port 8000

# Terminal 2: Start frontend  
cd frontend
npm install
npm run dev

# Browser: Open http://localhost:3000/chat
```

---

## ğŸ› ï¸ Installation

### Step 1: Install Ollama

**Windows/macOS:**
1. Download from [ollama.ai](https://ollama.ai)
2. Run installer
3. Open terminal and verify: `ollama --version`

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Step 2: Pull AI Model

```bash
# TinyLlama (recommended for 2-4GB RAM)
ollama pull tinyllama

# OR Phi3:mini (better quality, needs 4GB+ RAM)
ollama pull phi3:mini

# OR Llama 3.2 (best quality, needs 8GB+ RAM)
ollama pull llama3.2
```

### Step 3: Install Dependencies

```bash
# Clone repository
git clone https://github.com/yourusername/edgesoul.git
cd edgesoul

# Install backend dependencies
cd backend
pip install -r requirements.txt

# Install frontend dependencies  
cd ../frontend
npm install

# Install desktop dependencies
cd ../desktop
npm install
```

### Step 4: Run EdgeSoul

**Easy Way (Desktop App):**
```powershell
cd desktop
npm start
```

**Manual Way:**
```powershell
# Terminal 1: Backend
cd backend
python -m uvicorn main:app --reload

# Terminal 2: Frontend
cd frontend  
npm run dev

# Open: http://localhost:3000/chat
```

---

## ğŸ’» Usage

### Starting EdgeSoul

**Desktop App:**
```bash
cd desktop
npm start
```

**OR use batch scripts (Windows):**
```powershell
.\start-edgesoul.bat    # Start everything
.\stop-edgesoul.bat     # Stop everything
```

### Testing Emotional Intelligence

Try these messages:
```
"I'm feeling sad and lonely"
â†’ Empathetic support response

"I'm scolded but didn't do it"  
â†’ Detects sadness (victim context)

"make me feel confident"
â†’ Action-oriented empowering response

"help me calm down"
â†’ Breathing exercises and grounding
```

### Testing Knowledge Engine

Ask questions:
```
"What is quantum physics?"
"How do I learn Python?"
"Tell me a joke"
"Explain blockchain"
"Write code for bubble sort"
```

### Switching AI Models

```bash
cd backend
python switch_model.py phi3      # Switch to Phi3
python switch_model.py tiny      # Switch to TinyLlama
python switch_model.py llama3    # Switch to Llama 3.2
```

---

## ğŸ“ Project Structure

```
Edgesoul/
â”œâ”€â”€ backend/              # FastAPI backend
â”‚   â”œâ”€â”€ services/         # Emotion, Knowledge, Chat services
â”‚   â”œâ”€â”€ models/           # Pydantic data models
â”‚   â”œâ”€â”€ api/v1/          # REST API endpoints
â”‚   â””â”€â”€ main.py          # FastAPI app entry
â”‚
â”œâ”€â”€ frontend/            # Next.js frontend
â”‚   â”œâ”€â”€ app/             # App router pages
â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”œâ”€â”€ context/         # LocalAuth, Chat context
â”‚   â””â”€â”€ lib/             # Utilities
â”‚
â”œâ”€â”€ desktop/             # Electron desktop app
â”‚   â”œâ”€â”€ main.js          # Main process
â”‚   â”œâ”€â”€ preload.js       # Preload script
â”‚   â””â”€â”€ package.json     # Electron config
â”‚
â”œâ”€â”€ models/              # AI models
â”‚   â””â”€â”€ emotion_model.onnx  # Emotion detection
â”‚
â”œâ”€â”€ database/            # IndexedDB schemas
â”‚   â””â”€â”€ migrations/      # DB migrations
â”‚
â””â”€â”€ shared/              # Shared utilities
    â”œâ”€â”€ constants.py/ts  # Shared constants
    â””â”€â”€ utils.py/ts      # Shared functions
```

---

## ğŸ”§ Configuration

### Backend Config

**File:** `backend/core/config.py`

```python
ENABLE_EMOTION_DETECTION = True
ENABLE_KNOWLEDGE_REASONING = True
OLLAMA_HOST = "http://localhost:11434"
OLLAMA_MODEL = "tinyllama"
EMOTION_MODEL_PATH = "models/emotion_model.onnx"
```

### Frontend Config

**File:** `frontend/.env.local` (create this)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_NAME=EdgeSoul
```

### Desktop Config

**File:** `desktop/main.js`

```javascript
const BACKEND_PORT = 8000;
const FRONTEND_PORT = 3000;
```

---

## ğŸ¨ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Next.js 14, React 18, TypeScript, Tailwind CSS |
| **Backend** | FastAPI, Python 3.9, Pydantic, Uvicorn |
| **AI/ML** | Ollama (TinyLlama/Phi3), ONNX Runtime, Transformers |
| **Desktop** | Electron 27, electron-store, electron-updater |
| **Database** | IndexedDB (Dexie.js) for local storage |
| **Auth** | LocalAuth (no cloud, privacy-first) |

---

## ğŸ“Š Performance

| Model | Speed | Quality | RAM Required |
|-------|-------|---------|--------------|
| **TinyLlama** | 10-20s | Good â­â­â­ | 2.6GB |
| **Phi3:mini** | 3-5s | Excellent â­â­â­â­ | 4GB |
| **Llama 3.2** | 2-3s | Best â­â­â­â­â­ | 8GB |

**Emotion Detection:** Real-time (< 100ms)

---

## ğŸ§ª Testing

```bash
# Test emotion detection
cd backend
python test_emotion_quick.py

# Test knowledge engine  
python test_ollama_working.py

# Test complete system
python test_complete_system.py

# Test chatbot intelligence
python test_chatbot_intelligence.py
```

---

## ğŸ“¦ Building Desktop App

```bash
# Build for your platform
cd desktop
npm run build

# Build for specific platform
npm run build:win      # Windows installer
npm run build:mac      # macOS DMG
npm run build:linux    # Linux AppImage

# Output: desktop/dist/EdgeSoul-Setup-3.0.0.exe
```

---

## ğŸ”’ Privacy & Security

- âœ… **100% Local** - All processing on your machine
- âœ… **No Cloud** - No data sent to external servers
- âœ… **No Tracking** - No analytics, no telemetry
- âœ… **Open Source** - Audit the code yourself
- âœ… **Your Data** - Conversations stored locally in IndexedDB

---

## ğŸ†š EdgeSoul vs ChatGPT

| Feature | EdgeSoul | ChatGPT |
|---------|----------|---------|
| **Cost** | FREE âœ… | $20/month ğŸ’° |
| **Privacy** | 100% local âœ… | Cloud-based âŒ |
| **Internet** | Offline after setup âœ… | Always needs internet âŒ |
| **Emotion Detection** | Advanced (85%+) âœ… | Basic âŒ |
| **Response Speed** | 3-20s â±ï¸ | 2-3s âš¡ |
| **Knowledge** | Good â­â­â­ | Excellent â­â­â­â­â­â­ |
| **Customization** | Full control âœ… | Limited âŒ |

---

## ğŸ› Troubleshooting

### "Backend failed to start"
```bash
# Check Ollama is running
ollama list

# Restart Ollama
ollama serve

# Check Python dependencies
cd backend
pip install -r requirements.txt
```

### "Emotion model not found"
```bash
# Emotion model should be at:
models/emotion_model.onnx

# If missing, check backend/services/emotion_service.py
```

### "Responses too slow"
```bash
# Switch to faster model
cd backend
python switch_model.py phi3

# Check available RAM
# Close other applications to free memory
```

### "Desktop app won't start"
```bash
# Rebuild desktop app
cd desktop
npm install
npm start

# Check logs in console
```

---

## ğŸ“š Documentation

- **[SETUP.md](SETUP.md)** - Detailed installation guide
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - How to contribute
- **[backend/README.md](backend/README.md)** - Backend architecture
- **[models/README.md](models/README.md)** - Model information
- **[database/README.md](database/README.md)** - Database schemas

---

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Ways to contribute:**
- ğŸ› Report bugs
- âœ¨ Suggest features  
- ğŸ“ Improve documentation
- ğŸ”§ Submit pull requests
- â­ Star the repo!

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

You are free to use, modify, and distribute this software.

---

## ğŸ™ Acknowledgments

- **Ollama** - Local LLM inference
- **Hugging Face** - ML models and transformers
- **FastAPI** - Modern Python API framework
- **Next.js** - React framework
- **Electron** - Cross-platform desktop apps

---

## ğŸ“§ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/yourusername/edgesoul/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/yourusername/edgesoul/discussions)
- ğŸ“§ **Email**: support@edgesoul.app

---

<div align="center">

**Built with â¤ï¸ for privacy, emotion, and intelligence**

â­ Star us on GitHub if you like EdgeSoul!

[â¬† Back to top](#edgesoul-v30---emotional-ai-chatbot-desktop-app)

</div>
